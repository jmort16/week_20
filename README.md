# week_20

##### Document how to run the program you created in question 1 in a readme.md file in your repo. Be as clear as possible. Use proper markdown, and consider using screenshots. Be sure to briefly discuss why this kind of exercise might be helpful for NLP in your markdown. 

I started with a separate mapper.py and reducer.py file in VSCode like Alexis did in class.  But as I worked on my code, I decided that it was much better for me to include all chunks of the necessary code in one file, separating and labeling each part.

Because I used only one .py file, I did not use a map_reduce folder.  I just included my .py file in the repo with the .txt file and everything else.  Because of this, the code for my command line was less complicated than what we needed in class. (To be fair, my .py was MUCH more complicated however!)  My command line is shown in the image below, along with the first portion of my results -- showing the most commonly occurring words and punctuation.

![command_prompt_and_results](https://user-images.githubusercontent.com/90971714/155385470-f6eff1a8-c798-4b6a-a6b1-63280c0768b7.jpg)

The process of identifying words (and even specific characters), sorting them, grouping them, and counting occurrences is critical to many tasks in Natural Language Processing.  Knowing which words in a text occur more frequently gives insight as to the purpose or the focus of the text.  This has countless applications when applying NLP to the verbal data floating around in cyberspace every day.
